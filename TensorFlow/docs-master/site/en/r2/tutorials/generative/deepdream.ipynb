{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cmrFlYUtD9Tv"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "-xwaSGkjD9sL"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oBTK_JR2EBS9"
      },
      "source": [
        "# DeepDream\n",
        "\n",
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/beta/tutorials/generative/deepdream\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/deepdream.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/deepdream.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/tutorials/generative/deepdream.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HxBfLCOSEBQk"
      },
      "source": [
        "This tutorial contains a minimal implementation of DeepDream, as described in this [blog post](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) by Alexander Mordvintsev.\n",
        "\n",
        "DeepDream is an experiment that visualizes the patterns learned by a neural network. Similar to when a child watches clouds and tries to interpret random shapes, DeepDream over-interprets and enhances the patterns it sees in an image.\n",
        "\n",
        "It does so by forwarding an image through the network, then calculating the gradient of the image with respect to the activations of a particular layer. The image is then modified to increase these activations, enhancing the patterns seen by the network, and resulting in a dream-like image. This process was dubbed \"Inceptionism\" (a reference to [InceptionNet](https://arxiv.org/pdf/1409.4842.pdf), and the movie Inception).\n",
        "\n",
        "Let's demonstrate how you can make a neural network \"dream\" and enhance the surreal patterns it sees in an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lzlNLHf1c1Zl"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kE7Kx_R_NQfs"
      },
      "source": [
        "## Choose an image\n",
        "For this tutorial, let's use the image of a [Green Sea Turtle](https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FWUosOGeM2zz"
      },
      "outputs": [],
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/Green_Sea_Turtle_grazing_seagrass.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ufdACYo-NNmr"
      },
      "outputs": [],
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "def download(url):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  img = tf.keras.preprocessing.image.load_img(image_path)\n",
        "  return img\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "  return (img + 1.0)/2.0\n",
        "\n",
        "original_img = download(url)\n",
        "plt.imshow(original_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n92JLO0_S1PO"
      },
      "source": [
        "## Prepare the feature extraction model\n",
        "\n",
        "Let's load a pre-trained image classification model. For this task, a pre-trained [InceptionV3](https://keras.io/applications/#inceptionv3) is used, similar to the network originally used by the authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YTDZ403gSUIK"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MnOHAiOdUrh8"
      },
      "source": [
        "The idea in DeepDream is to choose a layer (or layers) and maximize the \"loss\" in a way that the image increasingly \"excites\" the layers. The complexity of the features incorporated depends on layers chosen by you, i.e, lower layers produce strokes or simple patterns, while deeper layers give sophisticated features in images, or even whole objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MeztYKpJUMxd"
      },
      "outputs": [],
      "source": [
        "# Maximize the activations of these arbitarily chosen layers\n",
        "names = ['mixed2', 'mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create our feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g3pin_-rMiq_"
      },
      "source": [
        "## Calculate loss\n",
        "\n",
        "The loss is the sum of the activations in the chosen layers. The loss is normalizaed at each layer so the contribution from larger layers does not outweigh smaller layers. Normally, loss is a quantity you wish to minimize via gradient descent. In DeepDream, you will maximize this loss via gradient ascent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p8NeOlixXivC"
      },
      "outputs": [],
      "source": [
        "def calc_loss(image):\n",
        "  image = image[None, ...]\n",
        "  layer_activations = dream_model(image)\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "  total_loss = tf.add_n(losses)\n",
        "  return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k4TCNsAUO9kI"
      },
      "source": [
        "## Gradient ascent\n",
        "\n",
        "Once you have calculated the loss for the chosen layers, all that is left is to calculate the gradients with respect to the image, and add them to the original image. \n",
        "\n",
        "Adding the gradients to the image enhances the patterns seen by the network. At each step, you will have created an image that increasingly excites the activations of certain layers in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kCIQ_Wi7z4tA"
      },
      "outputs": [],
      "source": [
        "img = tf.keras.preprocessing.image.img_to_array(original_img)\n",
        "img = tf.Variable(tf.keras.applications.inception_v3.preprocess_input(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8YevwXuUN7Ia"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BaQqrY9IzQqg"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def deepdream():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -calc_loss(img)\n",
        "  gradient = tape.gradient(loss, img)\n",
        "\n",
        "  optimizer.apply_gradients([(gradient, img)])\n",
        "  img.assign(tf.clip_by_value(img, -1, 1))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UUtC3T2zOBPY"
      },
      "source": [
        "## Result\n",
        "Brace yourself, things are going to get dreamy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zw--hysApaHi"
      },
      "outputs": [],
      "source": [
        "STEPS = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1YRGln2Ca7gs"
      },
      "outputs": [],
      "source": [
        "for step in range(STEPS):\n",
        "  loss = deepdream()\n",
        "  if step % 50 == 0:\n",
        "    clear_output(wait=True)\n",
        "    plt.imshow(deprocess(img))\n",
        "    plt.show()\n",
        "    print ('Step %d, loss %f' % (step, -1.0*loss))\n",
        "clear_output()\n",
        "plt.imshow(deprocess(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D7GYrE7gP-FL"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Now that you have seen how to make a network \"dream\", go ahead and experiment with a different combination of layers, a different [pre-trained model](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications) or your own neural network. You may also modify this code to maximize the activations of certain filters within a layer, as opposed to the layer as a whole.\n",
        "\n",
        "Finally, you may wish to see this complete [implementation](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream) in an older version of TensorFlow which includes additional tricks."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deepdream.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
